5.18单芯片 多处理器(chip muliprocessor, CMP) 在单个芯片上有多个核和cache。设计CMP的片上
二级cache时都会进行权衡。下表列出了两个基准测试程序在私有二级cache 和共享二级cache
中的缺失率和命中延迟。假设每32条指令发生-次一级 cache缺失。
                            私有        共享
基准测试程序A的每指令缺失    0.30%       0.12%
基准测试程序B的每指令缺失    0.06%       0.03%

下表列出了命中延迟:
私有cache  共享cache    存储器
5          20           180
5.18.1 [15] <5. 13 >对于每个基准测试程序，哪种cache设计更好?请用数据来支持你的结论。
5.18.2 [15] <5. 13 >共享cache的延迟随着CMP规模的增长而增长。如果共享cache的延迟加倍，请
选出最好的设计。当CMP中核的数量增加时，片下带宽就变成瓶颈，如果片下存储器访问延迟
加倍，请选出最好的设计。
5.18.3 [10] <5. 13>讨论共享二级cache和私有二级cache对于执行单线程、多线程以及多道程序负载
时的利弊情况;如果还有片上三级cache,请重新考虑这些问题。
5.18.4 [15] <5. 13 >假设两个基准测试程序的基本CPI都为1 (理想的二级cache)。如果使用非阻塞
cache能将同时发生二级cache缺失的平均次数从1提升到2,那么当使用共享二级cache时，性
能能提升多少?如果是私有二级cache,性能又能达到多少?
5.18.5[10]<5.13>假设新--代的处理器每18个月处理器核的数量就会翻倍。为了保证每个核的性能
处于相同水平，那么一个3年后的处理器需要多少片下存储器带宽?
5.18.6 [15] <5.13>考虑整个存储器层次结构,哪种优化可以改进同时发生的缺失数量?

答:
5.18.1
测试程序A
AMAT(private) = (1/32) * 5 + 0.0030 * 180 = 0.70
AMAT(shared) = (1/32) * 20 + 0.0012 * 180 = 0.84
测试程序B
AMAT(private) = (1/32) * 5 + 0.0006 * 180 = 0.26
AMAT(shared) = (1/32) * 40 + 0.0003 * 180 = 1.30
私有缓存在两个测试程序中的表现都要优于共有的

5.18.2
共享缓存延迟翻倍，私有缓存内存延迟翻倍。
测试程序A
AMAT(private) = (1 / 32) * 5 + 0.0030 * 360 = 1.24
AMAT(shared) = (1 / 32) * 40 + 0.0012 * 180 = 1.47
测试程序B
AMAT(private) = (1 / 32) * 5 + 0.0006 * 360 = 0.37
AMAT(shared) = (1 / 32) * 40 + 0.0003 * 180 = 1.30
私有缓存的表现依然都优于共享缓存

5.18.3
                  Shared L2                          Private L2
单线程            没有优点，没有缺点                 没有优点，没有缺点

多线程            共享缓存在线程高度绑定并          线程经常有自己私有的工作集，
                 需要频繁共享数据的工作负载下       用私有缓存可以避免缓存污染和线程
                 会有更好的表现                    之间的冲突缺失

多进程           没有优点，除了极少数情况下需要     进程之间的缓存保持私有和互相隔离。 
                 进行的进程间通信，缺点是高延迟     如果操作系统调度某一个进程时始终和一个核心
                                                  绑定会有更好的表现

让每个核心有自己私有的L2缓存和共享的L3缓存是一个效率上的妥协，他在许多工作负载上都有不错的表现
，许多现代处理器都采用了这种模式

5.18.4
一个非阻塞的共享二级缓存将减少二级缓存的延迟，允许一个CPU的命中被服务，
而另一个CPU的缺失被服务，或者允许两个CPU的缺失同时被服务。
假设多个内存指令可以同时执行，非阻塞式私有L2将减少延迟。

5.18.5
3 * 24 / 18 = 4

5.18.6
Additional DRAM bandwidth, dynamic memory schedulers, multi-banked memory systems, higher cache associativity, and additional levels of cache. 
f. Processor: out-of-order execution, larger load/store queue, multiple hardware threads;
Caches: more miss status handling registers (MSHR)
Memory: memory controller to support multiple outstanding memory requests
