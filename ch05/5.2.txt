5.2 cache 为处理器提供了一个高性能的存储器层次结构，因此十分重要。下面是一个32位存储器地
址引用的列表，给出的是字地址。
3, 180, 43, 2, 191, 88, 190, 14, 181, 44, 186, 253
5.2.1 [10]<5.3>已知一个直接映射的cache,有16个块，块大小为1个字。对于每次访问，请标识
出二进制地址、标记以及索引。假设cache最开始为空，那么请列出每次访问是命中还是缺失。
5.2.2 [10] <5.3>已知一个直接映射的cache,有8个块，块大小为2个字。对于每次访问，请标识出
二进制地址、标记以及索引。假设cache最开始为空，那么请列出每次访问是命中还是缺失。
5.2.3
[20] <5.3, 5.4>对已知的访问来优化cache的设计。这里有三种直接映射的cache设计方案，
每个容量都为8个字: C1 块大小为1个字，C2 块大小为2个字，C3块大小为4个字。根据缺失
率，哪种cache设计最好?如果缺失阻塞时间为25个周期，C1的访问时间为2个周期，C2 为3
个周期，C3为5个周期，那么哪种cache设计最好?
这里有许多对cache整体性能很重要的不同的设计参数。下面列出了对于不同的直接映射cache
设计的参数。
cache数据量: 32KiB
cache块大小: 2个字
cache访问时间: 1个周期
5.2.4 [15] <5.3>假定32位的地址,计算上面列出的cache所需的总位数。给定总的大小，找出最接
近的直接映像cache的总的大小，该cache块的大小为16个字长或更大。请解释为什么第二种
cache比第一种cache的访问速度更慢，尽管第二种cache的数据量更大。
5.2.5 [20]<5.3, 5.4>在一个2KiB的两路组相联cache.上产生- -系列读请求时的缺失率要比在表中
cache.上执行读请求的缺失率低。请给出-一个可能的解决方案,使得表中列出的cache的缺失率等
于或者低于2KiB cache的缺失率。讨论这种解决方案的优点和缺点。
5.2.6 [15] <5.3>5.3节的公式说明了用来索引直接映射cache的典型方法: (块地址) mod ( cache中
的块数)。假设地址为32位，cache 中有1024个块，考虑- -个不同的索引函数: (块地址 [31:
27]XOR块地址[26: 22])。 可以使用这个公式来索引直接映射的cache 吗?如果可以，请解释
原因，并且讨论可能需要对cache 做的一-些改动。如果不可以，请解释原因。

答:
5.2.1
Word Address      Binary Address      Tag      Index      Hit/Miss
3                 0000 0011            0        3           M
180               1011 0100            11       4           M
43                0010 1011            2        11          M
2                 0000 0010            0        2           M
191               1011 1111            11       15          M
88                0101 1000            5        8           M
190               1011 1110            11       14          M
14                0000 1110            0        14          M
181               1011 0101            11       5           M
44                0010 1100            2        12          M
186               1011 1010            11       10          M
253               1111 1101            15       13          M

5.2.2
Word Address      Binary Address      Tag        Index       Hit/Miss
3                 0000 0011            0           1           M
180               1011 0100            11          2           M
43                0010 1011            2           5           M
2                 0000 0010            0           1           H
191               1011 1111            11          7           M
88                0101 1000            5           4           M
190               1011 1110            11          7           H
14                0000 1110            0           7           M
181               1011 0101            11          2           H
44                0010 1100            2           6           M
186               1011 1010            11          5           M
253               1111 1101            15          6           M

5.2.3
Word Address      Binary Address      Tag      Cache1          Cache2            Cache3
                                            index  hit/miss   index  hit/miss   index  hit/miss
3                 0000 0011           0       3        M       1       M          0     M
180               1011 0100           22      4        M       2       M          1     M
43                0010 1011           5       3        M       1       M          0     M
2                 0000 0010           0       2        M       1       M          0     M
191               1011 1111           23      7        M       3       M          1     M
88                0101 1000           11      0        M       0       M          0     M
190               1011 1110           23      6        M       3       H          1     H
14                0000 1110           1       6        M       3       M          1     M
181               1011 0101           22      5        M       2       H          1     M
44                0010 1100           5       4        M       2       M          1     M
186               1011 1010           23      2        M       1       M          0     M
253               1111 1101           31      5        M       2       M          1     M

Cache1 miss rate = 100%
Cache1 total cycles = 12 * 25 + 12 * 2 = 324

Cache2 miss rate = 10 / 12 = 83%
Cahce2 total cycles = 10 * 25 + 12 * 3 = 286

Cache3 miss rate = 11 / 12 = 92%
Cache3 total cycles = 11 * 25 + 12 * 5 = 335
Cache2 provides the best performance.

5.2.4
首先，我们必须计算出初始cache配置中的缓存块的数量。为此，我们把32KiB除以4（每个字的字节数），
再除以2（每个块的字数）。这样我们就得到了4096个块和一个12位的索引域宽度。
我们也有一个1比特的字偏移量和一个2比特的字节偏移量。这使我们的标签字段大小为32-15=17位。
这些标签位，加上每个块的一个有效位，将需要18 X 4096 = 73728位或9216字节。
因此，总的缓冲区大小是9216 + 32768 = 41984字节。
总共的cache大小totalsize的计算方法为:
totalsize = datasize + (validbitsize + tagsize) * blocks
totalsize = 41984
datasize = blocks * blocksize * wordsize
wordsize = 4
tagsize = 32 - log2(blocks) - log2(blocksize) - log2(wordsize)
validbitsize = 1
将块大小从2字提升到16字会将标签位从17bits减去到14bits
为了算出有多少块，同理可得
41984 <= 64 * blocks + 15 * blocks
故同等大小可以有531个16字大的块，向2的幂次方我们最终会得到一个1024个块的cache
更大的块大小会提升命中时间和块缺失的代价，更少的块数量会导致更高的冲突缺失率


5.2.5
相联cahce是为了减少冲突缺失率而设计的，一个有着同样12-bit的索引位，但是不同的标记位的
读序列会导致很多不命中。对于读取序列0,32768,0,32768,0,32768...而言每次读取都会不命中，
然而两组相联并用LRU作为替换策略的cache，即使cache容量很小在首两次的冷缺失后也能次次都命中。

5.2.6
