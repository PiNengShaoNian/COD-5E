5.7这个练习研究了不同cache设计的效果，特别将关联的cache与5.4节中的直接映射的cache进行
比较。练习中使用的是练习题5.2中的地址流。
5.7.1 [10] <5.4>使用练习题5.2中的访问信息，对于一个3路组相联、块大小为2个字、总容量为
24个字、使用LRU替换算法的cache,指出cache中最终的内容。对每个访问，标识出索引位、
标记位、块偏移位，以及当前访问是命中还是缺失。
5.7.2 [10] <5.4 >使用练习题5.2中的访问信息，对于一个全相联、块大小为1个字、总容量为8个
字、使用LRU替换算法的cache,指出cache中最终的内容。对每个访问，标识出索引位、标记
位，以及当前访问是命中还是缺失。
5.7.3 [15]<5.4> 使用练习题5.2中的访问信息，对于一个全相联、块大小为2个字、总容量为8个
字、使用LRU替换算法的cache,请问缺失率是多少?如果替换为MRU (最近最常使用)算法，
缺失率是多少?在这些替换策略下，最好的情况下，cache 缺失率是多少?
多级cache是一-项重要技术，它在克服一级cache提供的有限空间的同时仍然保持了速度。假设
一个处理器的参数如下:
没有存储器                                          每条指令的          直接映射的         包含直接映射的           8路组相联            包含8路组相联的
阻塞的基本CPI      处理器速度      主存访问时间     一级cache缺失率      二级cache速度      二级cache的全局缺失率    的二级cache速度       二级cache全局缺失率
1.5                 2CHz            100ns               7%                 12个周期            3.5%                     28个周期             1.5%
5.7.4 [10] <5.4>计算表中处理器的CPI: 1)只有一级cache; 2)一个直接映射的二级cache; 3)一
个8路组相联的二级cache。如果主存访问时间加倍，CPI如何变化?如果主存访问时间减半,
CPI又如何变化?
5.7.5 [10] <5. 4>拥有比两级cache更多的cache 层次是可能的。已知上述的处理器拥有一个直接映射
的二级cache,一个设计者希望增加一个三级cache,其访问时间为50个周期，并且全局缺失率
降低到1.3%。这种设计能提供更好的性能吗?通常来说，增加一个三级cache的优点和缺点分
别是什么?
5.7.6 [20] <5. 4>在以前的处理器中，如Intel Pentium或Alpha 21264，二级cache在远离主处理器和
一级cache的片外(放置在不同的芯片上)。这使得二级cache很大，访问延迟也高得多，同时由
于二级cache以较低的频率运行，带宽通常也较低。假设一个512KiB的片外二级cache的全局缺
失率为4%。如果cache每增加512KiB容量可以降低0.7%的全局缺失率，并且cache总的访问时
间为50个周期，那么cache容量为多大时才能匹配表中直接映射的二级cache的性能?如果匹配
表中8路组相联的cache性能，cache 容量又需要是多少?

答:
5.7.1
该cache总共有24/3=8个块，所以索引位为3bits

Word Address     Binary Address    Tag    Index    Hit/Miss    Way0         Way1      Way2
3                0000 0011          0       1        M         T(1)=0

180              1011 0100          11      2        M         T(1)=0
                                                               T(2)=11

43               00101011           2       5        M         T(1)=0
                                                               T(2)=11
                                                               T(5)=2

2                0000 0010          0       1        M         T(1)=0        T(1)=0     
                                                               T(2)=11
                                                               T(5)=2

191              1011 1111          11      7        M         T(1)=0        T(1)=0
                                                               T(2)=11
                                                               T(5)=2
                                                               T(7)=11


5.7.2
因为是全相联并且块大小为一个字，所以word-address就等于标记
Tag       Hit/Miss       Contents
3            M              3         
180          M              3,180
43           M              3,180,43
2            M              3,180,43,2
191          M              3,180,43,2,191
88           M              3,180,43,2,191,88
190          M              3,180,43,2,191,88,190
14           M              3,180,43,2,191,88,190,14
181          M              181,180,43,2,191,88,190,14
44           M              181,44,43,2,191,88,190,14
186          M              181,44,186,2,191,88,190,14
253          M              181,44,186,253,191,88,190,14

5.7.3
Address      Tag       Hit/Miss       Contents
3             1           M             1
180           90          M             1,90
43            21          M             1,90,21
2             1           H             1,90,21
191           95          M             1,90,21,95
88            44          M             44,90,21,95
190           95          H             44,90,21,95
14            7           M             
181           90          H
44            22          M
186           143         M
253           126         M

最后的引用取代了缓存中的标签21，因为标签1和90在时间=3和时间=8的时候被重新使用，
而21在时间=2的时候还没有被使用。失误率=9/12=75% 这是最好的失误率，
因为没有任何一个区块的失误是以前从缓存中被驱逐的。事实上，唯一被驱逐的是标签21，
它只被引用了一次。

5.7.4
L1 only:
.07 * 100 = 7ns
CPI = 7ns / .5ns = 14

Direct mapped L2:
.07 * (12 + 0.035 * 100) = 1.1ns
CPI = celing(1.1ns / .5ns) = 3

8-way set associated L2:
.07 * (28 + 0.015 * 100) = 2.1ns
CPI = celing(2.1ns / .5ns) = 5

Doubled memory access time, direct mapped L2:
.07 * (12 + 0.035 * 200) = 1.3ns
CPI = celing(1.3ns / .5ns) = 3

Doubled memory access time, 8-way set associated L2:
.07 * (28 + 0.015 * 200) = 2.2ns
CPI = celing(2.2ns / .5ns) = 5

Halved memory access time, L1 only:
.07 * 50 = 3.5ns
CPI = 3.5ns / .5ns = 7

Halved memory access time, direct mapped L2:
.07 * (12 + 0.035 * 50) = 1.0ns
CPI = celing(1ns/.5ns) = 2

Halved memory access time, 8-way set associated L2:
.07 * (28 + 0.015 * 50) = 2.1ns
CPI = celing(2.1ns / .5ns) = 5

5.7.5
.07 * (12 + 0.035 * (50 + 0.013 * 100)) = 1.0ns
增加L3缓存确实减少了整体的内存访问时间，这是拥有L3缓存的主要优势。
缺点是，L3缓存会占用了其他类型功能单元的资源。

5.7.6
就算缺失率为0，50ns的访存时间,AMAT为.07 * 50 = 3.5ns,大于1.1ns和2.1ns的on-chip L2缓存
无论多大的cache都无法完成性能目标。